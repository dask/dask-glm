{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_glm.estimators import LogisticRegression\n",
    "from dask_glm.cupy.datasets import make_classification\n",
    "import time\n",
    "\n",
    "X, y = make_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['admm', 'lbfgs', 'newton', 'proximal_grad', 'gradient_descent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver admm took 263.742 ms to fit and 1.146 ms to predict\n",
      "Solver lbfgs took 13.935 ms to fit and 0.260 ms to predict\n",
      "Solver newton took 22.480 ms to fit and 0.248 ms to predict\n",
      "Solver proximal_grad took 11.700 ms to fit and 0.257 ms to predict\n",
      "Solver gradient_descent took 14.580 ms to fit and 0.257 ms to predict\n"
     ]
    }
   ],
   "source": [
    "for s in solvers:\n",
    "    lr = LogisticRegression(solver=s)\n",
    "\n",
    "    start_fit = time.time()\n",
    "    lr.fit(X, y)\n",
    "    end_fit = time.time()\n",
    "    lr.predict(X)\n",
    "    end_predict = time.time()\n",
    "\n",
    "    fit_time = (end_fit - start_fit) * 1000.0\n",
    "    predict_time = (end_predict - end_fit) * 1000.0\n",
    "\n",
    "    print(\"Solver %s took %0.3f ms to fit and %0.3f ms to predict\" % (s, fit_time,\n",
    "        predict_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
